core: {
    loguru_verbosity: 3
    hidpi: false
    debug_with_profiler: true //makes the profiler print when it starts and stops time
}

lattice_gpu: {
    hash_table_capacity: 10000 //good for shapenet which splat at around 1k for sigma 0.03 
    nr_sigmas: 1
    sigma_0: "0.5 3"  

}

tiny_loader: {
    imgs_path: "/media/rosu/Data/phd/c_ws/src/phenorob/neural_mvs/data/phenorob"
    pose_file_path: "/media/rosu/Data/phd/c_ws/src/phenorob/neural_mvs/data/phenorob/intrinsics_and_poses_world_raw_optimized.cfg"
    subsample_factor: 16
}

loader_vol_ref: {
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/augustus-ps"
    dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/lucy-ps"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/sokrates-ps"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/figure-mvs"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/sokrates-mvs"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/vase-mvs"
    autostart: false
    preload: true //preload the meshes in memory which is usually quite fast if they are small, or continously read them from memory

    nr_samples_to_skip: 0
    nr_samples_to_read: -1
    shuffle: false
    rgb_subsample_factor: 4
    depth_subsample_factor: 4
    load_rgb_with_valid_depth: true
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset

    scene_translation: [0.1, -0.1, 1.2]
    // scene_scale_multiplier: 0.7
    scene_scale_multiplier: 1.0


}

// loader_shapenet_img: {
//     dataset_path: "/media/rosu/Data/data/shapenet_images/ShapeNetRendering"
//     restrict_to_object: "chair" // you can leave it empty to get all of them or write any of (airplane, bag, cap, car, chair, earphone, guitar, knife, lamp, laptop, motorbike, mug, pistol, rocket, skateboard, table)
//     nr_samples_to_skip: 0
//     nr_samples_to_read: -1
//     // nr_samples_to_read: 10
//     subsample_factor: 4
//     shuffle: true
//     // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
//     do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
// }

loader_shapenet_img: {
    // dataset_path: "/media/rosu/Data/data/shapenet_images/ShapeNetRendering"
    // dataset_path: "/media/rosu/Data/data/shapenet_images/image"
    // dataset_depth_path: "/media/rosu/Data/data/shapenet_images/depth"

    dataset_path: "/media/rosu/Data/data/shapenet_images/renders/image"
    dataset_depth_path: "/media/rosu/Data/data/shapenet_images/renders/depth"
    
    // dataset_path: "/media/rosu/Data/data/shapenet_images/renders_2/image"
    // dataset_depth_path: "/media/rosu/Data/data/shapenet_images/renders_2/depth"

    // dataset_path: "/media/rosu/Data/data/shapenet_images/renders_test/image"
    // dataset_depth_path: "/media/rosu/Data/data/shapenet_images/renders_test/depth"

    restrict_to_object: "bench" // you can leave it empty to get all of them or write any of (plane, car, bench)
    nr_samples_to_skip: 1
    nr_samples_to_read: -1
    nr_imgs_to_read: -1 //nr of images for a certain scene that we want to read, a -1 means that we read all images which is around 36 
    subsample_factor: 2
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    difficulty: "easy"
    load_depth: false
    load_as_shell: true
}


loader_img: {
    autostart: false
    nr_cams: 1
    // rgb_path_cam_0: "/media/rosu/Data/phd/c_ws/src/phenorob/vae_from_others/VAE/data"
    rgb_path_cam_0: "/media/rosu/Data/data/celeba_dataset/data"
    imgs_to_skip: 0
    nr_images_to_read: -1
    // nr_images_to_read: 50
    only_rgb: true
    rgb_subsample_factor: 1
    shuffle: false
    sort_by_filename: false
    do_overfit: true
    // do_overfit: false
}

loader_nerf: {
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/chair"
    dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/drums"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/ficus"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/hotdog"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/lego"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/materials"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/mic"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/ship"
    subsample_factor: 2
    autostart: false
    shuffle: true
    mode: "train" //train, val, test
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    scene_scale_multiplier: 0.137
}

loader_colmap: {
    // dataset_path: "/media/rosu/Data/data/phenorob/data_from_home/christmas_thing/colmap/dense"
    dataset_path: "/media/rosu/Data/data/phenorob/data_from_home/fine_leaves_plant/colmap/dense"
    // subsample_factor: 8
    subsample_factor: 16
    // subsample_factor: 32
    // subsample_factor: 64
    autostart: false
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // scene_scale_multiplier: 0.121
    scene_scale_multiplier: 0.06
    load_imgs_with_transparency: false
}

loader_easypbr: {
    dataset_path: "/media/rosu/Data/data/easy_pbr_renders"
    object_name: "head"
    // object_name: "vase"
    subsample_factor: 16
    autostart: false
    shuffle: true
    mode: "train" //train, val, test
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // scene_scale_multiplier: 0.3
    scene_scale_multiplier: {
        head: 0.3
        vase: 0.0003
    }
}

loader_srn: {

    dataset_path: "/media/rosu/Data/data/pixel_nerf_data/"
    object_name: "car"
    // object_name: "chair"
    mode: "train"
    get_spiral_test_else_split_train: false //the spiral in the test set looks like crap so we rather split the train set in two. Splitting occurs when we set this to false
    autostart: false
    

    nr_samples_to_skip: 0
    nr_samples_to_read: -1
    nr_imgs_to_read: -1 //nr of images for a certain scene that we want to read, a -1 means that we read all images which is around 36 
    subsample_factor: 1
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    load_as_shell: true
    scene_scale_multiplier: {
        car: 0.3
        chair: 0.2
    }
}

loader_dtu: {

    dataset_path: "/media/rosu/Data/data/pixel_nerf_data/dtu_dataset/rs_dtu_4/DTU"
    mode: "train"
    restrict_to_scan_idx: -1
    autostart: false
    read_with_bg_thread: false
    

    subsample_factor: 1
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    load_as_shell: true
    scene_scale_multiplier: 0.15
    
}

loader_llff: {
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/fern"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/flower"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/fortress"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/horns"
    dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/leaves"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/orchids"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/room"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/trex"
    // subsample_factor: 64
    subsample_factor: 8
    autostart: false
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // scene_scale_multiplier: 0.01
    scene_scale_multiplier: 0.001
    // scene_scale_multiplier: 1.0
}



train: {
    // dataset_name: "volref" 
    // dataset_name: "nerf_lego"
    // dataset_name: "easypbr"
    // dataset_name: "colmap"
    // dataset_name: "shapenetimg" //currently has no good implementatinm of train and test split
    // dataset_name: "srn"
    // dataset_name: "dtu"
    dataset_name: "llff"
    with_viewer: true
    with_visdom: false
    with_debug_output: false
    with_error_checking: false
    batch_size: 1
    // lr:0.001  //for adam
    // lr:0.0003  //for adam
    lr:0.0001  //for adam
    // lr:0.00003  //for adam
    // lr:0.1  // for sgd
    // lr:0.03  //for radam
    // lr:0.5  // for apollo optimizer
    weight_decay: 3e-4 //from the adamWpaper
    // weight_decay: 1.0 //from the adamWpaper
    // weight_decay: 0.0 //from the adamWpaper
    // weight_decay: 0.1 //from the adamWpaper
    max_training_epochs: -1

    save_checkpoint: false
    // checkpoint_path: "/media/rosu/Data/phd/c_ws/src/phenorob/neural_mvs/saved_models/nerf_lego_RGB_S400_D_S200_withpos"
    // checkpoint_path: "/media/rosu/Data/phd/c_ws/src/phenorob/neural_mvs/saved_models/DTU_RGB_S400_D100_posconv_nosched"
    // checkpoint_path: "/media/rosu/Data/phd/c_ws/src/phenorob/neural_mvs/saved_models/nerf_drums_RGB_S400_D_S200_withpos"
    // checkpoint_path: "/media/rosu/Data/phd/c_ws/src/phenorob/neural_mvs/saved_models/orchids_s8_also1x1"
    checkpoint_path: "/media/rosu/Data/phd/c_ws/src/phenorob/neural_mvs/saved_models/flowers_s8_also1x1"
    // checkpoint_path: ""
    save_every_x_epoch: 50
}


model: {
    positions_mode: "uv+rgb"
    values_mode: "rgb"
    pointnet_layers: [16,32,64]
    pointnet_start_nr_channels: 16
    nr_downsamples: 1
    nr_blocks_down_stage: [2,2,2]
    nr_blocks_bottleneck: 3
    nr_blocks_up_stage: [2,2,2]
    nr_levels_down_with_normal_resnet: 3
    nr_levels_up_with_normal_resnet: 2
    compression_factor: 1.0
    dropout_last_layer: 0.0

    experiment: "none" 
}




visualization: {
    show_gui: true

    subsample_factor: 1
    enable_culling: false
    render_uv_to_gbuffer: true

    cam: {
        fov: 60 //can be a float value (fov: 30.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        near: "auto" //can be a float value (near: 0.01) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        far: "auto" //can be a float value (far: 10,0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        exposure: 1.2 //can be floar or "auto"
    }

    scene: {
        floor_visible: true
        floor_metric: true
    }


    ssao: {
        auto_settings: false
        enable_ssao: false
        ao_downsample: 0
        // kernel_radius: "auto" //can be a float value (kernel_radius: 10,0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        kernel_radius: 0.1 //can be a float value (kernel_radius: 10,0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        ao_power: 4
        ao_blur_sigma_spacial: 2.0
        ao_blur_sigma_depth: 1.0
    }

    bloom: {
        enable_bloom: false
        threshold: 0.85
        mip_map_lvl: 1
        blur_iters: 3
    }

    edl: {
        auto_settings: false
        enable_edl_lighting: true
        edl_strength: 7.0
    }

    background:{
        show_background_img: false
        background_img_path: ""
    }

    ibl: {
        enable_ibl: false
        show_environment_map: false
        // environment_map_path: "/media/rosu/Data/data/sibl/Desert_Highway/Road_to_MonumentValley_Ref.hdr"
        // environment_map_path: "/media/rosu/Data/data/sibl/Footprint_Court/Footprint_Court_2k.hdr"
        // environment_map_path: "/media/rosu/Data/data/sibl/Circus_Backstage/Circus_Backstage_3k.hdr"
        // environment_map_path: "/media/rosu/Data/data/sibl/canary_wharf_4k.hdr"
        environment_map_path: "sibl/Barcelona_Rooftops/Barce_Rooftop_C_3k.hdr"
        // environment_cubemap_resolution: 2048
        environment_cubemap_resolution: 32
        irradiance_cubemap_resolution: 32
        prefilter_cubemap_resolution: 32
        brdf_lut_resolution: 32
    }

    lights:{
        nr_spot_lights: 3
        spot_light_0: {
            power: "auto" //can be a float value (power: 1.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            color: "auto" //can be a vector of rgb [1.0, 1.0, 0.5] or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            create_shadow: true
            shadow_map_resolution: 2048
        }
        spot_light_1: {
            power: "auto" //can be a float value (power: 1.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            color: "auto" //can be a vector of rgb [1.0, 1.0, 0.5] or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            create_shadow: true
            shadow_map_resolution: 1024
        }
        spot_light_2: {
            power: "auto"  //can be a float value (power: 1.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            color: "auto" //can be a vector of rgb [1.0, 1.0, 0.5] or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            create_shadow: true
            shadow_map_resolution: 1024
        }
    }

}